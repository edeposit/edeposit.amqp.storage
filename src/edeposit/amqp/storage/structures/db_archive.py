#! /usr/bin/env python
# -*- coding: utf-8 -*-
#
# Interpreter version: python 2.7
#
# !!! DO NOT EDIT THIS FILE - THIS IS GENERATED FILE !!!
# Imports =====================================================================
import os
import base64
import zipfile
import os.path
import tempfile

from kwargs_obj import KwargsObj
from persistent import Persistent
from BalancedDiscStorage import BalancedDiscStorageZ

from ..settings import ARCHIVE_DIR
from ..settings import ARCH_PROJECT_KEY as PROJECT_KEY

from ..web_tools import compose_full_url

from shared import path_to_zip
from shared import read_as_base64

from archive import Archive


# Functions and classes =======================================================

# !!! DO NOT EDIT THIS FILE - THIS IS GENERATED FILE !!!
# !!! DO NOT EDIT THIS FILE - THIS IS GENERATED FILE !!!

class DBArchive(Persistent, KwargsObj):
    '''
    Database structure used to store basic metadata about Archives.

    Attributes:
        isbn (str): ISBN for the archive.
        uuid (str): UUID string to pair the archive with edeposit.
        aleph_id (str): ID used in aleph.
        dir_pointer (str): Pointer to the directory on the file server.
    '''
    def __init__(self, **kwargs):
        self.isbn = None
        self.uuid = None
        self.aleph_id = None
        self.dir_pointer = None

        self._kwargs_to_attributes(kwargs)

    @staticmethod
    def _save_to_unique_filename(pub):
        dirpath = ARCHIVE_DIR

        if not os.path.exists(dirpath):
            raise IOError("`%s` doesn't exists!" % dirpath)

        bdsz = BalancedDiscStorageZ(dirpath)

        # this is optimization for big files, which take big chunks of memory,
        # if copied multiple times as string
        with tempfile.TemporaryFile() as b64_file:
            b64_file.write(pub.b64_data)
            b64_file.flush()

            # unpack base64 data
            b64_file.seek(0)
            with tempfile.TemporaryFile() as unpacked_file:
                base64.decode(b64_file, unpacked_file)
                unpacked_file.flush()

                unpacked_file.seek(0)
                return bdsz.add_archive_as_dir(unpacked_file)

    @staticmethod
    def from_comm(pub):
        '''
        Convert communication namedtuple to this class.

        Args:
            pub (obj): :class:`.Archive` instance which will be converted.

        Returns:
            obj: :class:`DBArchive` instance.
        '''
        filename = None
        if pub.b64_data:
            filename = DBArchive._save_to_unique_filename(pub)

        return DBArchive(
            isbn=pub.isbn,
            uuid=pub.uuid,
            aleph_id=pub.aleph_id,

            dir_pointer=filename
        )

    @property
    def indexes(self):
        """
        Returns:
            list: List of strings, which may be used as indexes in DB.
        """
        return [
            "isbn",
            "uuid",
            "aleph_id",
            "dir_pointer",
        ]

    @property
    def project_key(self):
        return PROJECT_KEY

    def to_comm(self, light_request=False):
        '''
        Convert `self` to :class:`.Archive`.

        Returns:
            obj: :class:`.Archive` instance.
        '''
        data = None
        if not light_request:
            tmp_fn = path_to_zip(self.dir_pointer)
            data = read_as_base64(tmp_fn)
            os.unlink(tmp_fn)

        return Archive(
            isbn=self.isbn,
            uuid=self.uuid,
            aleph_id=self.aleph_id,

            b64_data=data,
            dir_pointer=self.dir_pointer,
        )

    def __eq__(self, obj):
        if not isinstance(obj, self.__class__):
            return False

        return (
            self.isbn == obj.isbn and
            self.uuid == obj.uuid and
            self.aleph_id == obj.aleph_id
        )

    def __ne__(self, obj):
        return not self.__eq__(obj)

    def __hash__(self):
        return hash(
            "".join(x.__repr__() for x in self.__dict__.values())
        )

# !!! DO NOT EDIT THIS FILE - THIS IS GENERATED FILE !!!
# !!! DO NOT EDIT THIS FILE - THIS IS GENERATED FILE !!!
